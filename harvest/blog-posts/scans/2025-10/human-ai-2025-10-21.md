---
kind: field_scan
river: human-ai
date: 2025-10-21
sources: [Hacker News, Simon Willison]
---

# Field Scan — Human-AI — 2025-10-21

## Hacker News

### LLMs can get "brain rot"
- **Date**: 2025-10-21
- **Link**: https://llm-brain-rot.github.io/
- **Excerpt**: [Research on model degradation]

### ChatGPT Atlas
- **Date**: 2025-10-21
- **Link**: https://chatgpt.com/atlas
- **Excerpt**: [OpenAI's new browser with AI features]

### Wikipedia says traffic is falling due to AI search summaries and social video
- **Date**: 2025-10-21
- **Link**: https://techcrunch.com/2025/10/18/wikipedia-says-traffic-is-falling-due-to-ai-search-summaries-and-social-video/
- **Excerpt**: Wikipedia reports declining traffic attributed to AI-powered search summaries and increased social video consumption

### Getting DeepSeek-OCR working on an Nvidia Spark via brute force with Claude Code
- **Date**: 2025-10-20
- **Link**: https://simonwillison.net/2025/Oct/20/deepseek-ocr-claude-code/
- **Excerpt**: [Technical writeup on getting AI OCR running]

### Neural audio codecs: how to get audio into LLMs
- **Date**: 2025-10-21
- **Link**: https://kyutai.org/next/codec-explainer
- **Excerpt**: [Technical explanation of audio encoding for LLMs]

---

## Simon Willison

### Don't let Claude Code delete your session logs
- **Date**: 2025-10-22
- **Link**: https://simonwillison.net/2025/Oct/22/claude-code-logs/
- **Excerpt**: Claude Code stores full logs of your sessions as newline-delimited JSON in ~/.claude/projects/encoded-directory/*.jsonl on your machine. I currently have 379MB of these! Unfortunately Claude Code has a nasty default behavior of deleting these after 30 days!

### Unseeable prompt injections in screenshots: more vulnerabilities in Comet and other AI browsers
- **Date**: 2025-10-21
- **Link**: https://simonwillison.net/2025/Oct/21/unseeable-prompt-injections/
- **Excerpt**: The Brave security team demonstrates prompt injection attacks where text on an image that's imperceptible to the human eye contains instructions that are interpreted by the LLM. Simply telling AI browser agents to navigate to a page with hidden instructions caused them to navigate to Gmail and exfiltrate private data.

### Introducing ChatGPT Atlas
- **Date**: 2025-10-21
- **Link**: https://simonwillison.net/2025/Oct/21/introducing-chatgpt-atlas/
- **Excerpt**: ChatGPT Atlas is a Mac-only web browser with ChatGPT-enabled features including "browser memories" and experimental "agent mode" where ChatGPT can take over navigating and interacting with pages. The security and privacy risks involved here still feel insurmountably high - I certainly won't be trusting any of these products until security researchers have given them a thorough beating.

### Quoting Bruce Schneier and Barath Raghavan
- **Date**: 2025-10-21
- **Link**: https://www.schneier.com/blog/archives/2025/10/agentic-ais-ooda-loop-problem.html
- **Excerpt**: "Prompt injection might be unsolvable in today's LLMs. LLMs process token sequences, but no mechanism exists to mark token privileges. Poisoned states generate poisoned outputs, which poison future states. Adversaries can craft inputs that corrupt future outputs."

### Claude Code for web - a new asynchronous coding agent from Anthropic
- **Date**: 2025-10-20
- **Link**: https://simonwillison.net/2025/Oct/20/claude-code-for-web/
- **Excerpt**: Anthropic launched Claude Code for web - an asynchronous coding agent similar to OpenAI's Codex Cloud and Google's Jules. It's their CLI tool wrapped in a container and configured to skip permissions, running tasks against GitHub repos and opening PRs.

---

## Scan Notes
- Strong pattern around AI browser agents and security vulnerabilities
- Multiple sources discussing prompt injection risks
- New AI tools launching (ChatGPT Atlas, Claude Code for web)
- Concerns about AI impact on existing infrastructure (Wikipedia traffic)
- Technical advances (audio codecs, OCR) alongside safety concerns
